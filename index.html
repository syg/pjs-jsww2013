<!doctype html>
<html lang="en">

  <head>
    <meta charset="utf-8">

    <title>PJS</title>

    <meta name="author" content="Shu-yu Guo">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="css/reveal.min.css">
    <link rel="stylesheet" href="css/theme/rfrn.css" id="theme">

    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/pygments.css">

    <!-- If the query includes 'print-pdf', use the PDF print sheet -->
    <script>
      document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
    </script>

    <!--[if lt IE 9]>
	<script src="lib/js/html5shiv.js"></script>
	<![endif]-->
  </head>

  <body>

    <div class="reveal">

      <!-- Any section element inside of this container is displayed as a slide -->
      <div class="slides">

	<section data-state="darktitle">
	  <h1>PJS</h1>
	  <h3>A Misunderstood Implementation</h3>
	  <div id="title-info">
            <span>Shu-yu Guo / <a href="mailto:shu@mozilla.com">shu</a></span>
            <br>
            <span style="font-size: 80%;">JS Work Week Santa Cruz 2013</span>
	  </div>
	</section>

        <section>
          <h2>Data Parallelism for JS</h2>
          <p>Yes, it's a collaboration with Intel...</p>
          <p class="fragment"><i>But</i>, it is standards track, and we have the final word.</p>
        </section>

        <section>
          <h2>API</h2>
          <p>Provide functional, higher-order operations on arrays and binary data.</p>
<div class="highlight"><pre><span class="kd">var</span> <span class="nx">a</span> <span class="o">=</span> <span class="p">[];</span>
<span class="p">...</span> <span class="c1">// initialize a</span>
<span class="kd">var</span> <span class="nx">a2</span> <span class="o">=</span> <span class="nx">a</span><span class="p">.</span><span class="nx">pmap</span><span class="p">(</span><span class="nx">kernel</span><span class="p">);</span>
</pre></div>
        </section>

        <section>
          <aside class="notes">
            So what kind of kernel functions can be run in parallel? Roughly, ones without observable side effects. When this happens, the entire operation falls back to sequential execution. Internally, we bail out before executing the side effect, then restart the entire computation.
          </aside>

          <h2>What Runs in Parallel?</h2>
<div class="highlight"><pre><span class="kd">var</span> <span class="nx">upvar</span><span class="p">;</span>
<span class="nx">a</span><span class="p">.</span><span class="nx">pmap</span><span class="p">(</span><span class="kd">function</span> <span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
  <span class="nx">upvar</span> <span class="o">=</span> <span class="nx">x</span><span class="p">;</span> <span class="c1">// observable side effect! entire op runs sequentially</span>
<span class="p">});</span>
</pre></div>
        </section>


        <section>
          <aside class="notes">
            For an engine as venerable as SM, making the interpreter threadsafe was a nonstarter.
          </aside>

          <h2>How to parallelize JS?</h2>
          <p>Making interpreter threadsafe a nonstarter.</p>
          <p class="fragment">Use the JIT!</p>
          <ul class="fragment">
            <li>Many fast paths already threadsafe</li>
            <li>Mark which instructions are safe/unsafe at compile time</li>
            <li>Analysis framework already exists</li>
          </ul>
        </section>

        <section>
          <aside class="notes">
            So how does this all work? The majority of this talk will be to give technical overviews of the various parts of the infrastructure for PJS. We'll go from the outside in: self-hosted JS first, then the engine internals.
          </aside>

          <h2>Under the Hood</h2>
          <ul>
            <li>Self-hosting</li>
            <ul>
              <li><code>ForkJoin</code></li>
              <li>Warmups</li>
            </ul>
          </ul>
          <ul class="fragment">
            <li>Parallel execution mode</li>
            <ul>
              <li>Transitive compilation</li>
              <li>Ensuring purity</li>
            </ul>
          </ul>
          <ul class="fragment">
            <li>Challenges</li>
            <ul>
              <li>Recompiles</li>
              <li>Context sensitivity</li>
            </ul>
          </ul>
        </section>

        <section>
          <h2>Self-hosting</h2>
          <p>Leverage the engine; improvements made for PJS feed back into the engine.</p>
          <p>Makes nesting calls to parallel operations easier.</p>
          <p>Allows for rapid iteration.</p>
          <p>Implementation at <code>builtin/ParallelArray.{h,cpp,js}</code></p>
        </section>

        <section>
          <aside class="notes">
            Some implementation details, like error checking and scheduling the index bounds between slices, are elided.
          </aside>

          <h2>Parallel Map</h2>
<div class="highlight"><pre><span class="kd">function</span> <span class="nx">ArrayParallelMap</span><span class="p">(</span><span class="nx">func</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">buffer</span> <span class="o">=</span> <span class="nx">NewDenseArray</span><span class="p">(</span><span class="k">this</span><span class="p">.</span><span class="nx">length</span><span class="p">);</span>
  <span class="kd">var</span> <span class="nx">numSlices</span> <span class="o">=</span> <span class="nx">ForkJoinSlices</span><span class="p">();</span>
  <span class="nx">ForkJoin</span><span class="p">(</span><span class="nx">mapSlice</span><span class="p">,</span> <span class="nx">CheckParallel</span><span class="p">(</span><span class="nx">mode</span><span class="p">));</span>
  <span class="k">return</span> <span class="nx">buffer</span><span class="p">;</span>

  <span class="kd">function</span> <span class="nx">mapSlice</span><span class="p">(</span><span class="nx">sliceId</span><span class="p">,</span> <span class="nx">numSlices</span><span class="p">,</span> <span class="nx">warmup</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="p">[</span><span class="nx">indexStart</span><span class="p">,</span> <span class="nx">indexEnd</span><span class="p">]</span> <span class="o">=</span> <span class="nx">ComputeIndexBounds</span><span class="p">(</span><span class="nx">sliceId</span><span class="p">,</span> <span class="nx">warmup</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="nx">indexStart</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">indexEnd</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span>
      <span class="nx">UnsafeSetElement</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">i</span><span class="p">,</span> <span class="nx">func</span><span class="p">(</span><span class="nx">self</span><span class="p">[</span><span class="nx">i</span><span class="p">],</span> <span class="nx">i</span><span class="p">,</span> <span class="nx">self</span><span class="p">));</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
        </section>

        <section>
          <h2>Intrinsics</h2>
          <p>Vanilla JS obviously does not suffice. Unsafe intrinsics to the rescue!</p>
          <ul>
            <li><code>ForkJoin</code></li>
            <li class="fragment"><code>ForkJoinSlices</code></li>
            <li class="fragment"><code>NewDenseArray</code></li>
            <li class="fragment"><code>UnsafeSetElement</code></li>
          </ul>
          <p class="fragment">Inlinings of frequently used ones, like <code>UnsafeSetElement</code>, exist in Ion.</p>
        </section>

        <section>
          <h2>ForkJoin</h2>
          <p>Signature:</p>
          <code>(func : function, feedback : maybe function) -> void</code><br><br>
          <p>Kernel signature:</p>
          <code>(sliceId : int, numSlices : int, warmup : bool) -> void</code><br><br>
          <p>The kernel function is supposed to track the work it needs to do on its own given its arguments.</p>
        </section>

        <section>
          <h2>ForkJoin</h2>
          <p>Compiles function's callgraph in Ion for <i>parallel mode</i>.</p>
          <p>Spawns N (defaults to number of cores - 1) threads in fork-join style.</p>
          <p>Threads do not have access to <code>JSContext</code>. Context is a <code>ForkJoinSlice</code>, stored in TLS.</p>
          <p>Parallel allocation: each thread has own allocator; arenas moved back to the main allocator after joining.</p>
          <p>Stop-the-world GC.</p>
          <p>Implementation at <code>vm/ForkJoin.{h,cpp}</code></p>
        </section>

        <section>
          <h2>Warmups</h2>
          <p>What is that <code>warmup</code> flag?</p>
          <div class="fragment">
            <p>No TI info = can't JIT. No JIT code = no parallel execution.</p>
            <p>If kernel function isn't compiled, run sequentially and warmup.</p>
            <p>If compiled function bails out, re-warmup.</p>
            <p>Turn off parallel execution if bailouts too frequent.</p>
          </div>
        </section>

        <section>
          <h2>Parallel Execution Mode</h2>
          <p>Calling <code>ForkJoin(f)</code> warms up <code>f</code> and compiles it for parallel mode.</p>
          <p class="fragment">Different <code>IonScript</code> named <code>parallelIon</code>.</p>
          <p class="fragment">Analyzed for safety before compiled.</p>
          <p class="fragment">Cannot call into other modes.</p>
          <p class="fragment">Bails out back to <code>ForkJoin</code> call, not point of bailout in interpreter/baseline.</p>
        </section>

        <section>
          <h2>Default Mode</h2>
          <p>Sequential execution is default in all phases of Ion compilation.</p>
        </section>

        <section>
          <aside class="notes">
            Because we can't call into other modes or fallback without bailing out the entire fork-join computation, we have to compile the entire callgraph beforehand.
          </aside>

          <h2>Transitive Compilation</h2>
          <h4>Problem</h4>
          <p>Cannot compile a script without aborting of fork-join; calls to uncompiled scripts abort.</p>
          <div class="fragment">
            <h4>Solution</h4>
            <p>Need to compile the kernel and all reachable callees before spinning up threads.</p>
            <p>Use TI info (singleton types and <code>TypeObject::interpretedFunction</code>) to determine callgraph.</p>
            <p>Fixed-point algorithm. Script invalidations can happen inside transitive compilation due to type propagation.</p>
          </div>
        </section>

        <section>
          <aside class="notes">
            As mentioned before, we don't allow side-effectful functions to be run in parallel. Crashes and races are bad. So how do we prevent this?
          </aside>

          <h2>Ensuring Purity</h2>
          <p>Analysis phase to mark MIR as <i>safe</i> (checks, if any, are runtime) or <i>unsafe</i>. See <code>ion/ParallelArrayAnalysis.cpp</code></p>

          <div class="fragment">
            <p>In general, MIR are categorized as:</p>
            <ul>
              <li>Always safe (<code>Goto</code>, <code>TypeBarrier</code>, etc)</li>
              <li>Always unsafe (<code>ToString</code>, <code>CallSetElement</code>, etc)</li>
              <li>Write-guarded (<code>StoreFixedSlot</code>, etc)</li>
              <li>Specialized (arithmetic ops)</li>
            </ul>
          </div>
        </section>

        <section>
          <h2>Safe MIR</h2>
          <p>These MIR either:</p>
          <ul>
            <li>&hellip;are pure (e.g. <code>Goto</code>, <code>Box</code>)</li>
            <li>&hellip;have runtime checks (e.g. <code>TypeBarrier</code>)</li>
            <li>&hellip;have alternate codegen with checks (e.g. <code>Call</code>, <code>NewObject</code>)</li>
          </ul>
        </section>

        <section>
          <h2>Unsafe MIR</h2>
          <p>Basic blocks with unsafe MIR are replaced with bailouts.</p>
          <p>Scripts with unsafe entry blocks are disabled.</p>
          <p class="fragment">Some currently-marked unsafe MIR might be overly conservative. We simply haven't had the time to look at / support them.</p>
        </section>

        <section>
          <h2>Write-guarded MIR</h2>
          <p>Recall each thread has its own allocator.</p>
          <p>Some MIR (e.g. <code>StoreFixedSlot</code>) safe as long as we guard on writing only to thread-local objects.</p>
        </section>

        <section>
          <h2>Specialized</h2>
          <p>Some operations (e.g. <code>Add</code>) are safe so long as we know they won't call out into side-effectful hooks.</p>
        </section>

        <section>
          <h2>Aside: MPar*</h2>
          <p>Currently, there are alternate versions of MIR for parallel mode, such as <code>MParNew</code>. These all take an <code>MForkJoinSlice</code> as an extra operand.</p>
          <p>Going forward, we'll be consolidating some of those (bug 869313).</p>
        </section>

        <section>
          <h2>Self-modifying Code</h2>
          <div>
            <h4>Problem</h4>
            <p>PICs are not threadsafe, as they call into the VM and modify code.</p>
          </div>
          <div class="fragment">
            <h4>Solution</h4>
            <p>Pure paths in the VM + atomic attaching of generated stubs.</p>
          </div>
        </section>

        <section>
          <h2>GetProperty: VM Path</h2>
          <p>Getting a property is language-level pure, but VM-level impure!</p>
          <div class="fragment">
            <h4>Problem</h4>
            <p>Shape table may hashify.</p>
          </div>
          <div class="fragment">
            <h4>Solution</h4>
            <p>Carve out pure, contextless paths to do property get and lookup that never hashifies. May be independently useful. See <code>GetPropertyPure</code>.</p>
          </div>
        </section>

        <section>
          <h2>Atomic Stub Attaching</h2>
          <div class="fragment">
            <h4>Problem</h4>
            <p>Patching the last jump of an IC daisy chain is not atomic; also have to worry about alignment, ARM caches, etc.</p>
          </div>
          <div class="fragment">
            <h4>Solution</h4>
            <p>Lock the VM when attaching a new stub.</p>
            <p>Introduce a &ldquo;stub attaching policy&rdquo; class: <code>IonCache::StubAttacher</code>.</p>
            <p>Separate 2 base classes, <code>RepatchIonCache</code> and <code>DispatchIonCache</code>.</p>
          </div>
        </section>

        <section>
          <aside class="notes">
            lastJump_ is the last jump in the stub daisy chain. In the beginning it points to the update cache function.
          </aside>

          <h2>Repatch - Initial State</h2>
<pre>
         JIT Code
        +--------+   .---------------.
        |        |   |               |
        |========|   v +----------+  |
        |== IC ==|====>| Cache Fn |  |
        |========|     +----------+  |
        |        |<=#       #        |
        |        |  #=======#        |
        +--------+  Rejoin path      |
            |________                |
                    |                |
          Repatch   |                |
            IC      |                |
          Entry     |                |
        +------------+               |
        | lastJump_  |---------------/
        +------------+
        |    ...     |
        +------------+
</pre>
        </section>

        <section>
          <aside class="notes">
            Attaching a stub patches the previous lastJump_ and updates lastJump_ to point to the new, last jump. Stubs are always appended.
          </aside>

          <h2>Repatch - Stub</h2>
<pre>
         JIT Code
        +--------+ #=======================#
        |        | #                       v
        |========| #   +----------+     +------+
        |== IC ==|=#   | Cache Fn |<====| Stub |
        |========|     +----------+  ^  +------+
        |        |<=#      #         |     #
        |        |  #======#=========|=====#
        +--------+      Rejoin path  |
            |________                |
                    |                |
          Repatch   |                |
            IC      |                |
          Entry     |                |
        +------------+               |
        | lastJump_  |---------------/
        +------------+
        |    ...     |
        +------------+
</pre>
        </section>

        <section>
          <aside class="notes">
            No already-running code is patched. The IC entry keeps a firstStub_ pointer which points to the first stub to jump to. The jump is first loaded from the IC entry, then jumped to. Stubs are prepended.
          </aside>

          <h2>Dispatch - Initial State</h2>
<pre>
         JIT Code
        +--------+                                 .-------.
        |        |                                 v       |
        |========|     +---------------+     +----------+  |
        |== IC ==|====>| Load and jump |====>| Cache Fn |  |
        |========|     +---------------+     +----------+  |
        |        |<=#           *                #         |
        |        |  #===========*================#         |
        +--------+       Rejoin * path                     |
            |________           *                          |
                    |           *                          |
          Dispatch  |           *                          |
            IC    **|************                          |
          Entry   * |                                      |
        +------------+                                     |
        | firstStub_ |-------------------------------------/
        +------------+
        |    ...     |
        +------------+
</pre>
        </section>

        <section>
          <aside class="notes">
            Assign the address of the new stub to firstStub_. The new stub jumps to the previous address held by firstStub_ on failure. No already-running instruction stream is patched at the expense of an extra load.
          </aside>

          <h2>Dispatch - Stub</h2>
<pre>
         JIT Code
        +--------+                        #=====================#   .-----.
        |        |                        #                     v   v     |
        |========|     +---------------+  #  +----------+     +------+    |
        |== IC ==|====>| Load and jump |==#  | Cache Fn |<====| Stub |    |
        |========|     +---------------+     +----------+     +------+    |
        |        |<=#           *                #                #       |
        |        |  #===========*================#================#       |
        +--------+       Rejoin * path                                    |
            |________           *                                         |
                    |           *                                         |
          Dispatch  |           *                                         |
            IC    **|************                                         |
          Entry   * |                                                     |
        +------------+                                                    |
        | firstStub_ |----------------------------------------------------/
        +------------+
        |    ...     |
        +------------+
</pre>
        </section>

        <section>
          <h2>Big VM Lock</h2>
          <p>It is unfortunate that we have to lock the entire VM when attaching a new stub (the code allocator depends on the <code>JSContext</code>). In the future, finer-grained locks would be preferred.
        </section>

        <section>
          <h2>Recompiles</h2>
          <p>We must exit parallel execution to recompile invalidated scripts.</p>
          <p>Recompiles not so bad for sequential execution, but hurts performance greatly in parallel execution.</p>
          <p>Very noticeable jitters!</p>
          <p class="fragment">Must be able to reach a fixed state w.r.t. recompiles quickly.</p>
        </section>

        <section>
          <aside class="notes">
            In the example, if we wait until g, then f, get invalidated, then recompile the entire callgraph, we'll do wasted work.
          </aside>

          <h2>Recompiles</h2>
          <div>
            <h4>Problem</h4>
            <p>Suppose our callgraph is <code>f -&gt; g -&gt; h</code>.
              If <code>h</code> gets invalidated, when do we recompile it?</p>
          </div>
          <div class="fragment">
            <h4>Solution</h4>
            <p>We store the possible targets that a function may call and a dirty bit in <code>parallelIon</code>.</p>
            <p>Upon invalidation, flip the dirty bit all the way up the call chain to check for compiledness of its possible targets upon next call to <code>ForkJoin</code>.</p>
          </div>
        </section>

        <section>
          <h2>Recompile Jitters</h2>
          <p>Use off-main-thread-compilation to help with jitters in parallel mode, much like in sequential mode.</p>
        </section>

        <section>
          <h2>Context Sensitivity</h2>
          <p>Context sensitivity in type info is important for writing parametric polymorphic code (like collections) in JS.</p>
          <p>Doubly so for PJS, where recompiles hurt more, and a greater desire to stable type state quicker.</p>
        </section>

        <section>
          <aside class="notes">
            Sites where type info will be conflated across different calls are highlighted.
          </aside>

          <h2>Parallel Map</h2>
<div class="highlight"><pre><span class="kd">function</span> <span class="nx">ArrayParallelMap</span><span class="p">(</span><span class="nx" style="background-color: yellow;">func</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx" style="background-color: yellow;">buffer</span> <span class="o">=</span> <span class="nx">NewDenseArray</span><span class="p">(</span><span class="k" style="background-color: yellow;">this</span><span class="p">.</span><span class="nx">length</span><span class="p">);</span>
  <span class="kd">var</span> <span class="nx">numSlices</span> <span class="o">=</span> <span class="nx">ForkJoinSlices</span><span class="p">();</span>
  <span class="nx">ForkJoin</span><span class="p">(</span><span class="nx">mapSlice</span><span class="p">,</span> <span class="nx">CheckParallel</span><span class="p">(</span><span class="nx">mode</span><span class="p">));</span>
  <span class="k">return</span> <span class="nx" style="background-color: yellow;">buffer</span><span class="p">;</span>

  <span class="kd">function</span> <span class="nx">mapSlice</span><span class="p">(</span><span class="nx">sliceId</span><span class="p">,</span> <span class="nx">numSlices</span><span class="p">,</span> <span class="nx">warmup</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="p">[</span><span class="nx">indexStart</span><span class="p">,</span> <span class="nx">indexEnd</span><span class="p">]</span> <span class="o">=</span> <span class="nx">ComputeIndexBounds</span><span class="p">(</span><span class="nx">sliceId</span><span class="p">,</span> <span class="nx">warmup</span><span class="p">);</span>
    <span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="nx">indexStart</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">indexEnd</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span>
      <span class="nx">UnsafeSetElement</span><span class="p">(</span><span class="nx" style="background-color: yellow;">buffer</span><span class="p">,</span> <span class="nx">i</span><span class="p">,</span> <span class="nx" style="background-color: yellow;">func</span><span class="p">(</span><span  style="background-color: yellow;"><span class="nx">self</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span></span>, <span class="nx">i</span><span class="p">,</span> <span class="nx" style="background-color: yellow;">self</span><span class="p">));</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
        </section>

        <section>
          <h2>Callsite Cloning</h2>
          <h4>Problem</h4>
          <p>Some mechanism of monomorphizing functions around arguments and <code>this</code>.</p>
          <div class="fragment">
            <h4>Solution</h4>
            <p>Clone marked, self-hosted functions at callsites.</p>
          </div>
        </section>

        <section>
          <h2>Callsite Cloning</h2>
          <p>For an operation like <code>map</code>, we want to monomorphize on its kernel function argument and <code>this</code>. Callsite cloning is a decently close approximation.</p>
          <p class="fragment">The ability to specialize refine types at inline sites does not subsume all callsite cloning use case.</p>
        </section>

        <section>
          <h2>Callsite Cloning</h2>
          <p>Functions marked explicitly with</p>
          <code>SetScriptHints(f, { cloneAtCallsite: true })</code>
          <div class="fragment">
            <p>Cloned via deep script cloning.
              <ul style="padding-left: 1em;">
                <li>Has a backlink to original function for things like <code>function.caller</code></li>
                <li>Argument, <code>this</code>, and return typesets flow back to original</li>
              </ul>
            </p>
          </div>
          <p class="fragment">Each unique callsite (script and PC pair) of <code>f</code> has a clone of <code>f</code>. Hash table of callsite to clone kept in <code>cx-&gt;compartment-&gt;callsiteClones</code>.
          <p class="fragment">Always cloned in the interpreter. Cloned with best effort in the JITs.</p>
        </section>

        <section>
          <h2>Summary</h2>
          <p>PJS is self-hosted with <code>ForkJoin</code>.</p>
          <p>Only pure, Ion-compiled code runs in parallel.</p>
          <p>Extra efforts taken to cut down on recompiles and type instability.</p>
        </section>

        <section>
          <h3>Nothing too shady!</h3>
        </section>

        <section>
          <h2>Thank you!</h2>
          <div style="display: inline-block;">
            <img src="nmatsakis.jpeg" style="height: 220px;"><br>
            <span style="font-size: 80%;">Niko Matsakis / <a href="mailto:nmatsakis@mozilla.com">nmatsakis</a></span>
          </div>
          <div style="display: inline-block;">
            <img src="pnkfelix.png" style="height: 220px;"><br>
            <span style="font-size: 80%;">Felix Klock II / <a href="pnkfelix@mozilla.com">pnkfelix</a></span>
          </div>
          <div style="display: inline-block;">
            <img src="shu.jpg" style="height: 220px;"><br>
            <span style="font-size: 80%;">Shu-yu Guo / <a href="shu@mozilla.com">shu</a></span>
          </div>
        </section>

      </div>

    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.min.js"></script>

    <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
      controls: true,
      progress: false,
      history: true,
      center: true,
      rollingLinks: false,

      theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
      transition: Reveal.getQueryHash().transition || 'fade', // default/cube/page/concave/zoom/linear/fade/none

      // Optional libraries used to extend on reveal.js
      dependencies: [
      { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
      { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
      // { src: 'plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; } }
      // { src: 'plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
      ]
      });

    </script>

  </body>
</html>
